{
	"title": {
		"media": {
			"url": "https://miro.medium.com/v2/resize:fit:1400/1*c_fiB-YgbnMl6nntYGBMHQ.jpeg",
			"caption": "Machine Learning ",
			"credit": "<a href= \"https://medium.com/@azadsingh_35336/introduction-to-machine-learning-20c919899efe\"> Illustration from Azad Singh: </a>"
		},
		"text": {
			"headline": " Advancements in Machine Learning Through The Years (1949 - Present) ",
			"text": "<p> Machine learning is a branch of artificial intelligence that enables systems to learn from data and improve over time without being explicitly programmed. This timeline highlights key breakthroughs and innovations that have shaped the development of modern machine learning, from its early theoretical foundations to today's powerful AI applications. </p>"
		}
	},
	"events": [
		{
			"media": {
				"url": "https://www.datasciencecentral.com/wp-content/uploads/2021/10/2808336983.png",
				"caption": " The Hebbian Learning",
				"credit": "<a href=\"https://www.datasciencecentral.com/learning-rules-in-neural-network/\"> Illustration from Sheetal Sharma: </a>"
			},
			"start_date": {
				"year": "1949"
			},
			"text": {
				"headline": "Hebbian Learning",
				"text": "<p>In 1949, Donald Hebb introduced a model of brain cell interaction in his book \"The Organization of Behavior\", laying the groundwork for neural networks. Hebbian learning, introduced by Hebb, is a foundational principle in neuroscience and early machine learning, often summarized as \"neurons that fire together, wire together.\" He proposed that learning occurs through the strengthening of connections between neurons—an idea that later influenced the development of artificial neural networks.</p>"
			}
		},
		{
			"media": {
				"url": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTEckcWM4tuZ3obe9otrZtW6Gn5LK81jhOBRg&s",
				"caption": "Photo of Alan Turing",
				"credit": "<a href=\"https://www.linkedin.com/pulse/alan-turing-godfather-ai-his-test-arthur-wetzel-cr3mf\">From Arthur W.'s Article: </a>"
			},
			"start_date": {
				"year": "1950"
			},
			"text": {
				"headline": "The Turing Test",
				"text": "\"Can machines think?\" This was the question posed by Alan Turing, the pioneer of modern computing, in his seminal paper \"Computing Machinery and Intelligence.\" In this work, Turing proposed a method to evaluate a machine’s intelligence—what is now known as the Turing Test. The test challenges a machine to imitate human responses well enough to convince a human judge that it, too, is human. If the judge cannot reliably distinguish the machine from a human, the machine is said to have passed the test.  "
			}
		},
		{
			"media": {
				"url": "https://news.cornell.edu/sites/default/files/styles/story_thumbnail_xlarge/public/2019-09/0925_rosenblatt_main.jpg?itok=SE0aS7ds",
				"caption": "Frank Rosenblatt working on the “electronic profile analyzing computer”",
				"credit": "<a href=\"https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon\"> Photo from Cornell Chronicles:  </a>"
			},
			"start_date": {
				"year": "1957"
			},
			"text": {
				"headline": "The Perceptron",
				"text": " In 1957, Frank Rosenblatt combined Hebb’s neural theory with Arthur Samuel’s machine learning work to create the perceptron, originally designed as software for the IBM 704 and installed in the custom-built Mark I perceptron machine for image recognition. Though hailed as the first successful neuro-computer, the Mark I fell short in recognizing complex patterns like faces, leading to disillusionment and a decline in neural network research. This setback stalled progress until a resurgence of interest in the 1990s revived machine learning efforts."
			}
		},
		{
			"media": {
				"url": "https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/arc/cf/ul/g/7d/e9/1959_ibm7090_as_checkers.component.xl.ts=1702909365747.jpg/content/adobe-cms/us/en/history/early-games/jcr:content/root/leadspace",
				"caption": "The Father of Machine Learning",
				"credit": "<a href=\"https://www.ibm.com/history/early-games\"> Photo from IBM:  </a>"
			},
			"start_date": {
				"year": "1959"
			},
			"text": {
				"headline": "Samuel's Game of Checkers",
				"text": "Arthur Samuel of IBM, who coined the term \"machine learning\" in 1952, developed a checkers-playing program that became one of the earliest examples of self-learning software (1959). Due to limited memory, he implemented alpha-beta pruning and designed a scoring function to evaluate board positions. The program also used a minimax strategy, laying the foundation for what later became the minimax algorithm."
			}
		},
		{
			"media": {
				"url": "https://youtu.be/E85l6euMsd0?si=JgY1sb8TF-N6fhR_ ",
				"caption": "Traveling Salesman Problem (Nearest Neighbor Algorithm)",
				"credit": "<a href=\"https://youtu.be/E85l6euMsd0?si=Zg4xhhkyV2ZGV7O6\"> Video from Jonathan Mitchell:  </a>"
			},
			"start_date": {
				"year": "1967"
			},
			"text": {
				"headline": "The Nearest Neighbor Algorithm",
				"text": "In 1967, the nearest neighbor algorithm was introduced, marking a key step in early pattern recognition and route mapping. It was one of the first methods used to discuss the traveling salesperson problem by having the program visit the closest unvisited city at each step. While Marcello Pelillo is credited with the \"nearest neighbor rule,\" he attributes its origins to the influential 1967 paper by Cover and Hart."
			}
		},
		{
			"media": {
				"url": "https://youtu.be/WZDMNM36PsM?si=AWkcTRIZJgiHbBSU ",
				"caption": "Backpropagation Neural Network - How it Works e.g. Counting",
				"credit": "<a href=\"https://youtu.be/WZDMNM36PsM?si=AWkcTRIZJgiHbBSU\"> Video from RimstarOrg: </a>"
			},
			"start_date": {
				"year": "1974"
			},
			"text": {
				"headline": "Development of Backpropagation",
				"text": "With the emergence of utilizing multilayer perceptrons in the 1960's, the need to adjust weights in hidden layers became critical. This led to the development of the backpropagation algorithm, first applied to neural networks by Paul Werbos in 1974, and mathematically based on Seppo Linnainmaa's 1970 work on reverse-mode automatic differentiation. This breakthrough enabled networks to learn by propagating error signals backward. "
			}
		},
		{
			"media": {
				"url": " https://miro.medium.com/v2/resize:fit:720/format:webp/1*qzIPSA-HQlefxxZnPlb-2w.png",
				"caption": " Illustration of AdaBoost Algorithm",
				"credit": "<a href=\"https://pub.towardsai.net/all-about-adaboost-ba232b5521e9\"> From Akash Dawari:   </a>"
			},
			"start_date": {
				"year": "1995"
			},
			"text": {
				"headline": "Shift to a Data-Driven Approach: Boosting Algorithm",
				"text": " In the 1990s, machine learning shifted from symbolic AI to a data-driven approach, focusing on solving practical problems using statistical methods. This period also saw the introduction of boosting, beginning with Robert Schapire’s 1990 paper on turning weak learners into strong ones—laying the groundwork for powerful algorithms like AdaBoost, which emerged in 1995."
			}
		},
		{
			"media": {
				"url": " https://towardsdatascience.com/wp-content/uploads/2022/02/17cMfenu76BZCzdKWCfBABA-2048x1717.png ",
				"caption": " Long Short-Term Memory (LSTM) Neural Networks ",
				"credit": "<a href=\"https://towardsdatascience.com/lstm-recurrent-neural-networks-how-to-teach-a-network-to-remember-the-past-55e54c2ff22e/ \"> Illustration from Saul Dobilas: </a>"
			},
			"start_date": {
				"year": "1997"
			},
			"text": {
				"headline": "Long Short-Term Memory (LSTM) Network",
				"text": "<p> Long Short-Term Memory (LSTM), introduced by Hochreiter and Schmidhuber in 1997, enabled deep learning systems to remember information across long sequences—crucial for speech recognition. In 2015, Google reported a 49% improvement in its voice recognition system using CTC-trained LSTMs, marking a major step in real-world applications of deep learning. </p>"
			}
		},
		{
			"media": {
				"url": "https://www.researchgate.net/profile/V-Chandran-2/publication/27470866/figure/fig1/AS:309999730479111@1450921103831/Examples-of-FRGC-3D-data-for-three-classes-of-expression-strength-a-Neutral-b-Small.png",
				"caption": " Examples of FRGC 3D data for three classes of expression strength: (a) Neutral (b) Small Expression and (c) Large Expression",
				"credit": "<a href=\"https://www.researchgate.net/figure/Examples-of-FRGC-3D-data-for-three-classes-of-expression-strength-a-Neutral-b-Small_fig1_27470866\"> Photo from V. Chandran: </a>"
			},
			"start_date": {
				"year": "2006"
			},
			"text": {
				"headline": "Facial Recognition Breakthrough",
				"text": "<p>In 2006, the Face Recognition Grand Challenge, led by the National Institute of Standards and Technology (NIST), assessed leading facial recognition algorithms of the time. The evaluation used 3D facial scans, iris data, and high-resolution images. Results showed the latest algorithms were 10 times more accurate than those from 2002, and 100 times more accurate than the systems used in 1995. </p>"
			}
		},
		{
			"media": {
				"url": "https://aggity.com/wp-content/uploads/2023/04/chatgpt1.jpg",
				"caption": "Open AI's ChatGPT",
				"credit": "<a href=\"https://aggity.com/en/how-to-create-quality-content-with-gpt-chat/\"> Photo from Aggity: </a>"
			},
			"start_date": {
				"year": "2020"
			},
			"text": {
				"headline": " GPT-3 & ChatGPT",
				"text": "<p> In 2020, OpenAI introduced GPT-3, a powerful language model with 175 billion parameters, marking a major leap in natural language processing. It became the foundation for tools like ChatGPT, capable of generating human-like text and assisting in a wide range of tasks. New methods like instruction fine-tuning aim to make AI more adaptable, enabling a single model to perform diverse tasks with minimal prompting.</p>"
			}
		},
		{
			"media": {
				"url": "https://365datascience.com/resources/blog/thumb@1024_w0mewfnp44o-04-image-future-machine-learning-1-01.webp",
				"caption": "Machine Learning Trends to Watch in the Future",
				"credit": "<a href=\"https://365datascience.com/trending/future-of-machine-learning/\"> Photo from Nicolette Son: </a>"
			},
			"start_date": {
				"year": "2025"
			},
			"text": {
				"headline": " Future of Machine Learning",
				"text": "<p>The future of machine learning (ML) is expected to focus on distributed computing, ethical AI practices, automation through AutoML, and integration with advanced technologies like quantum computing. These developments aim to address complex challenges in sectors like healthcare, finance, and transportation. Emerging trends also emphasize greater accessibility, stronger data privacy, and a commitment to sustainable and transparent AI systems.</p>"
			}
		},
		{
			"media": {
				"url": "https://xiengineering.com/wp-content/uploads/2023/10/AdobeStock_519767884-1-scaled.jpeg",
				"caption": "Machine Learning",
				"credit": "<a href=\"https://xiengineering.com/machine-learning-fundamentals-applications-and-expert-insight/\"> Image source: </a>"
			},
			"start_date": {
				"year": "2026"
			},
			"text": {
				"headline": "References",
				"text": "<p> Alarcon, N., & Alarcon, N. (2023, June 12). OpenAI Presents GPT-3, a 175 Billion Parameters Language Model. NVIDIA Technical Blog. <a href=\"https://developer.nvidia.com/blog/openai-presents-gpt-3-a-175-billion-parameters-language-model/\">https://developer.nvidia.com/blog/openai-presents-gpt-3-a-175-billion-parameters-language-model/</a><br> Foote, K. D. (2024, September 25). A brief history of machine learning. DATAVERSITY. <a href=\"https://www.dataversity.net/a-brief-history-of-machine-learning/\">https://www.dataversity.net/a-brief-history-of-machine-learning/</a><br> Karjian, R. (2024, June 13). History and evolution of machine learning: A timeline. WhatIs. <a href=\"https://www.techtarget.com/whatis/feature/History-and-evolution-of-machine-learning-A-timeline\">https://www.techtarget.com/whatis/feature/History-and-evolution-of-machine-learning-A-timeline</a><br> What is the Future of Machine Learning? | Mission. (2025, February 28). <a href=\"https://www.missioncloud.com/blog/what-is-the-future-of-machine-learning#:~:text=Data%20Privacy%20and%20Security%20Concerns,and%20maintain%20compliance%20with%20regulations.\">https://www.missioncloud.com/blog/what-is-the-future-of-machine-learning</a><br> Wikipedia contributors. (2025, August 20). Machine learning. Wikipedia. <a href=\"https://en.wikipedia.org/wiki/Machine_learning\">https://en.wikipedia.org/wiki/Machine_learning</a></p>"
			}
		}
	]
}